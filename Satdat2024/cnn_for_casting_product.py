# -*- coding: utf-8 -*-
"""CNN for casting product.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/19GtGa9mzP7ejGhUMbYDXHuwFum3N3z9e

# Introduction

One of the ways to manufacture metal products is through a process called casting, in which liquid metal is poured into a mold to harden. Casting products may contain irregularities or defects and thus must be inspected prior shipping to ensure that customer specifications are met. Accurate inspection is important because defective products can cause rejection of the whole production order by the customers, resulting in financial loss for the casting company.

Visual inspection is a non-destructive technique to detect flaws on casting products. It involves an inspector looking at each test piece with the naked eye and then classifying the product as either defective or OK based on his assessment. Due to its reliance on human factors, however, visual inspection is prone to misclassification and can be time-consuming.

This project explores automation of visual inspection with computer vision. A deep learning model called convolutional neural networks (CNN) is created to distinguish images of defective and non-defective castings.
"""

# Import relevant libraries for the project
import os
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.models import Sequential, load_model
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout
from tensorflow.keras.callbacks import ModelCheckpoint
from tensorflow.keras.optimizers import Adam
from sklearn.metrics import confusion_matrix, classification_report
plt.style.use('ggplot')

"""# Dataset

Our casting product data comprises top-view JPEG images of cast submersible pump impellers, provided by [Pilot Technocast](https://pilottechnocast.com/). Images were captured with Canon EOS 1300D DSLR camera. Every images are 300×300 pixels in size and already labeled as either `def_front` (defective castings) or `ok_front` (non-defective).

The folder `train` in the input directory contains images that are used for model training/validation. Images located in the `test` folder are used to test the trained model's performance.
"""

# Specify directory of train data
dir_train = '/kaggle/input/real-life-industrial-dataset-of-casting-product/casting_data/casting_data/train/'
dir_train_def = dir_train+'def_front/'  # Class label: Defective
dir_train_ok = dir_train+'ok_front/'    # Class label: OK

# Specify directory of test data
dir_test = '/kaggle/input/real-life-industrial-dataset-of-casting-product/casting_data/casting_data/test/'
dir_test_def = dir_test+'def_front/'
dir_test_ok = dir_test+'ok_front/'

# Plot samples of defective and non-defective casting
fig, axes = plt.subplots(1, 2, figsize=(8,4))
sample_def = plt.imread(dir_train_def+os.listdir(dir_train_def)[0])
sample_ok = plt.imread(dir_train_ok+os.listdir(dir_train_ok)[0])
axes[0].imshow(sample_def)
axes[1].imshow(sample_ok)
axes[0].set_title('Casting Sample: Defective', loc='left')
axes[1].set_title('Casting Sample: OK', loc='left')
axes[0].grid(False)
axes[1].grid(False)
plt.show()

from google.colab import drive
drive.mount('/content/drive')

"""We are performing a classification predictive modeling which involves assigning a class label (`Defective` or `OK`) for a given image of casting product. To prevent the model from making a biased prediction, the dataset must be checked for class imbalance. As shown in the following plot, there is uneven distribution between `Defective` and `OK`. However, considering the class imbalance is only by a small amount (6:4), the problem can be treated like a normal classification predictive modeling."""

# Create dataframe of class distribution
n_train = [len(os.listdir(dir_train_def)), len(os.listdir(dir_train_ok))]
n_test = [len(os.listdir(dir_test_def)), len(os.listdir(dir_test_ok))]
dist_df = pd.DataFrame(
    data=[n_train, n_test],
    columns=['Defective', 'OK'],
    index=['Train', 'Test'])

# Visualize class distribution
ax = dist_df.T.plot(kind='bar', stacked=True, rot=0, figsize=(8,5), colormap='Accent')
ax.set_title('Class Distribution', loc='left', weight='bold')
for bar in ax.patches:
    ax.text(bar.get_x()+bar.get_width()-0.25,
            bar.get_y()+bar.get_height()/2,
            int(bar.get_height()),
            ha='center', va='center', color='white')
pct_def = 100*dist_df['Defective'].values.sum()/dist_df.values.sum()
pct_ok = 100-pct_def
ax.set_xticklabels([f'Class: Defective ({pct_def:.0f}%)',
                    f'Class: OK ({pct_ok:.0f}%)'], weight='bold')
plt.show()

"""# Data Preprocessing

The first step of preparing the data is to normalize pixel values (originally between 0 and 255) to a range of 0 to 1. This is done by passing the `rescale` arguments on instances of Keras ImageDataGenerator for train and test sets.

With the train set generator we specify `validation_split=0.2` to reserve 20% of data for validation. The function `flow_from_directory()` is then used on the data generators for each of `train/` and `test/` directories. Arguments for data generation are also specified:
- Target image size is 300×300 pixels
- `color_mode='grayscale'` to convert images as having 1 channel
- Define class mapping: `0` for `OK`, `1` for `Defective`
- `class_mode='binary'`  since there are two classes
- Batch size fixed at 64
"""

# Define instances of ImageDataGenerator
train_gen = ImageDataGenerator(rescale=1./255, validation_split=0.2)
test_gen = ImageDataGenerator(rescale=1./255)

# Specify parameters/arguments for data generation
img_size, batch_size, rand_seed = (300, 300), 64, 0
arg_train = {'target_size': img_size,
             'color_mode': 'grayscale',
             'classes': {'ok_front': 0,
                         'def_front': 1},
             'class_mode': 'binary',
             'batch_size': batch_size,
             'seed': rand_seed}
arg_test = {'target_size': img_size,
            'color_mode': 'grayscale',
            'classes': {'ok_front': 0,
                        'def_front': 1},
            'class_mode': 'binary',
            'batch_size': batch_size,
            'seed': rand_seed,
            'shuffle': False}

# Generate data by iterating through directories
train_set = train_gen.flow_from_directory(
    directory=dir_train, subset='training', **arg_train)
valid_set = train_gen.flow_from_directory(
    directory=dir_train, subset='validation', **arg_train)
test_set = test_gen.flow_from_directory(
    directory=dir_test, **arg_test)

"""# Model Building

We will use convolutional neural networks to approach the problem of classifying whether a casting is Defective or OK based on the given image. Almost universally used in computer vision applications, convolutional neural networks (CNN, convnets) is a type of deep-learning model that can look at groups of adjacent pixels in an area of an image and learn to find spatial patterns.

<p style="text-align:center;">
    <img src="https://cezannec.github.io/assets/cnn_intro/CNN_ex.png" alt="CNN architecture" width="500">
</p>
<p style="text-align:center;font-style:italic">Image classification with a typical CNN architecture</p>

As pictured above, CNN is made up of a number of layers: a series of convolutional layers (with activation), pooling layers, and at least one final fully-connected layer that produces a set of class scores for a given image. The convolutional layers of a CNN act as feature extractors; they extract shape and color patterns from the pixel values of training images.

More in-depth explanations of how each CNN layer works can be found on [this awesome blog by Cezanne Camacho](https://cezannec.github.io/Convolutional_Neural_Networks/).

For our model, we will adapt the general architectural principles of the [VGG models](https://arxiv.org/abs/1409.1556). The architecture involves stacking convolutional layers with small 3×3 filters followed by a max pooling layer, together forming a block. These blocks can be repeated with increasing number of filters such as 32, 64, 128, 256.

Padding is used on the convolutional layers to ensure same height and width between input and output. ReLU activation function is applied on every layer except the last one. Since a binary classification task requires a prediction of either a value of 0 or 1, the output layer is defined with 1 node and a sigmoid activation function.

The model is fit with Adam optimizer (learning rate of 0.001) and with binary cross-entropy loss function. The metric with which to monitor model training is accuracy.
"""

# Define CNN model architecture
cnn_model = Sequential([
    # First block
    Conv2D(32, 3, activation='relu', padding='same', strides=2,
           input_shape=img_size+(1,)),
    MaxPooling2D(pool_size=2, strides=2),
    # Second block
    Conv2D(64, 3, activation='relu', padding='same', strides=2),
    MaxPooling2D(pool_size=2, strides=2),
    # Flatenning
    Flatten(),
    # Fully connected layers
    Dense(128, activation='relu'),
    Dense(1, activation='sigmoid')        # Only 1 output
])

# Compile model
cnn_model.compile(
    optimizer=Adam(learning_rate=0.001),  # Default lr
    loss='binary_crossentropy',
    metrics=['accuracy'])

# Display summary of model architecture
cnn_model.summary()

"""# Model Training and Evaluation

The model is trained for 20 epochs, each requiring 83 steps for all image batches to pass through the network. The `ModelCheckpoint` callback is specified to save the model at an epoch that yields the best value of `val_loss` (when it is most minimized). We will later load the saved model to make predictions on the test set.
"""

# Commented out IPython magic to ensure Python compatibility.
# %%time
# 
# # Fit model using train set and validation set
# n_epochs = 20
# cnn_model.fit(
#     train_set,
#     validation_data=valid_set,
#     epochs=n_epochs,
#     callbacks=ModelCheckpoint(
#         'CNN_Casting_Inspection.hdf5',
#         save_best_only=True,
#         monitor='val_loss'),
#     verbose=1)

# Plot learning curve from model history
histo_dict = cnn_model.history.history
histo_df = pd.DataFrame(histo_dict, index=range(1,n_epochs+1))
fig, ax = plt.subplots(figsize=(8,5))
for m in histo_df.columns:
    ax.plot(histo_df.index, m, data=histo_df)
ax.set_xlabel('Epoch')
ax.set_title('Learning Curve', loc='left', weight='bold')
ax.legend()
plt.show()

"""Accuracies of the model generally increase while loss decrease with increasing epoch. It can also be observed that training and validation curves are closely aligned, indicating that the model does not result in overfitting and may perform well on classifying images from the test set. Epoch 20 achieved best performance with the following results:
- 99.81% training accuracy,
- 98.94% validation accuracy,
- 0.76% training loss, and
- 2.78% validation loss.

# Using Model to Classify New Images

The trained model is used to predict the class of images that weren't previously included in the training and validation process. The classification will output a probability score between 0-1 and a threshold value of 0.5 is specified to separate the classes. A probability score that is equal to or greater than this threshold is classified as `Defective`, otherwise `OK`.
"""

# Load saved model
best_model = load_model('./CNN_Casting_Inspection.hdf5')

# Make predictions on images in the test set
y_pred_prob = best_model.predict(test_set, verbose=1)
y_pred = (y_pred_prob >= 0.5).reshape(-1,)
y_true = test_set.classes[test_set.index_array]

# Visualize the confusion matrix
fig, ax = plt.subplots(figsize=(4,3))
ax = sns.heatmap(confusion_matrix(y_true,y_pred), annot=True,
                 annot_kws={'size':14, 'weight':'bold'},
                 fmt='d', cbar=False, cmap='Blues')
ax.set_xticklabels(['OK', 'Defective'])
ax.set_yticklabels(['OK', 'Defective'], va='center')
plt.tick_params(axis='both', labelsize=14, length=0)
plt.ylabel('Actual', size=14, weight='bold')
plt.xlabel('Predicted', size=14, weight='bold')
plt.show()

print(classification_report(y_true, y_pred, digits=4))

"""An overall classification accuracy of 99.44% is achieved by the trained model which means that, out of 715 test images, there are 4 cases of misclassification. On predicting whether or not an image is of `Defective` casting, the model scores 99.78% on recall, 99.34% on precision, and 99.56% on F1-score.

False negatives (mis-detections), i.e., cases when `Defective` castings are predicted as `OK`, must be minimized as it may cause revenue loss for the casting company due to rejection of the whole production order by customer. On the other hand, false positives (over-detection) may increase waste and production cost, not to mention unnecessary downtime.

The metric recall helps us evaluate model performance when the cost of false negatives is high. Alternatively, when the cost of false positives is high, the metric precision is prioritized. However, since both cases of misclassification negatively impact the business, F1-score can be selected as a performance metric. F1-score is an overall measure of a model's accuracy that combines precision and recall.

The following plots show prediction results and the probability score of some images from the test set. The visualization codes are adapted from [this notebook by Tomy Tjandra](https://www.kaggle.com/tomythoven/casting-inspection-with-data-augmentation-cnn).
"""

class_map = {0: 'OK', 1: 'Defective'}
images, labels = next(iter(test_set))
images = images.reshape(batch_size,*img_size)

fig, axes = plt.subplots(1, 3, figsize=(9, 4))
fig.suptitle('Prediction on Test Images', y=0.98, weight='bold', size=14)
for ax, img, label in zip(axes.flat, images, labels):
    ax.imshow(img, cmap='gray')
    [[pred_prob]] = best_model.predict(img.reshape(1, *img_size, -1))
    pred_label = class_map[int(pred_prob>=0.5)]
    true_label = class_map[label]
    prob_class = 100*pred_prob if pred_label=='Defective' else 100*(1-pred_prob)
    ax.set_title(f'Actual: {true_label}', size=12)
    ax.set_xlabel(f'Predicted: {pred_label} ({prob_class:.2f}%)',
                  color='g' if pred_label==true_label else 'r')
    ax.set_xticks([])
    ax.set_yticks([])
plt.tight_layout()
plt.show()

misclassified = np.nonzero(y_pred != y_true)[0]
batch_num = misclassified//batch_size
image_num = misclassified%batch_size

fig, axes = plt.subplots(1, 4, figsize=(12, 4))
fig.suptitle('Misclassified Test Images', y=0.98, weight='bold', size=14)
for ax, bnum, inum in zip(axes.flat, batch_num, image_num):
    images, labels = test_set[bnum]
    img = images[inum]
    ax.imshow(img.reshape(*img_size), cmap='gray')
    [[pred_prob]] = best_model.predict(img.reshape(1, *img_size, -1))
    pred_label = class_map[int(pred_prob>=0.5)]
    true_label = class_map[labels[inum]]
    prob_class = 100*pred_prob if pred_label=='Defective' else 100*(1-pred_prob)
    ax.set_title(f'Actual: {true_label}', size=12)
    ax.set_xlabel(f'Predicted: {pred_label} ({prob_class:.2f}%)',
                  color='g' if pred_label==true_label else 'r')
    ax.set_xticks([])
    ax.set_yticks([])
plt.tight_layout()
plt.show()

"""# Conclusion

A convolutional neural networks model was created to classify images of a casting product as either Defective or OK and achieved a good performance based on F1-score (99.56%). Results of this project suggest viability of deep learning method in automating visual inspection. Incorporation of this method in the production line can provide support for trained inspectors in making better assessments of product quality.
"""