{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 1300891,
          "sourceType": "datasetVersion",
          "datasetId": 487456
        }
      ],
      "dockerImageVersionId": 30066,
      "isInternetEnabled": false,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction\n",
        "\n",
        "One of the ways to manufacture metal products is through a process called casting, in which liquid metal is poured into a mold to harden. Casting products may contain irregularities or defects and thus must be inspected prior shipping to ensure that customer specifications are met. Accurate inspection is important because defective products can cause rejection of the whole production order by the customers, resulting in financial loss for the casting company.\n",
        "\n",
        "Visual inspection is a non-destructive technique to detect flaws on casting products. It involves an inspector looking at each test piece with the naked eye and then classifying the product as either defective or OK based on his assessment. Due to its reliance on human factors, however, visual inspection is prone to misclassification and can be time-consuming.\n",
        "\n",
        "This project explores automation of visual inspection with computer vision. A deep learning model called convolutional neural networks (CNN) is created to distinguish images of defective and non-defective castings."
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "id": "Sbrcm9AvKvfa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import relevant libraries for the project\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential, load_model\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "plt.style.use('ggplot')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-08-19T10:57:21.069266Z",
          "iopub.execute_input": "2021-08-19T10:57:21.069694Z",
          "iopub.status.idle": "2021-08-19T10:57:22.971311Z",
          "shell.execute_reply.started": "2021-08-19T10:57:21.069601Z",
          "shell.execute_reply": "2021-08-19T10:57:22.970559Z"
        },
        "trusted": true,
        "id": "JXbxN_TDKvfd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset\n",
        "\n",
        "Our casting product data comprises top-view JPEG images of cast submersible pump impellers, provided by [Pilot Technocast](https://pilottechnocast.com/). Images were captured with Canon EOS 1300D DSLR camera. Every images are 300Ã—300 pixels in size and already labeled as either `def_front` (defective castings) or `ok_front` (non-defective).\n",
        "\n",
        "The folder `train` in the input directory contains images that are used for model training/validation. Images located in the `test` folder are used to test the trained model's performance."
      ],
      "metadata": {
        "id": "AbxIfa0rKvff"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Specify directory of train data\n",
        "dir_train = '/kaggle/input/real-life-industrial-dataset-of-casting-product/casting_data/casting_data/train/'\n",
        "dir_train_def = dir_train+'def_front/'  # Class label: Defective\n",
        "dir_train_ok = dir_train+'ok_front/'    # Class label: OK\n",
        "\n",
        "# Specify directory of test data\n",
        "dir_test = '/kaggle/input/real-life-industrial-dataset-of-casting-product/casting_data/casting_data/test/'\n",
        "dir_test_def = dir_test+'def_front/'\n",
        "dir_test_ok = dir_test+'ok_front/'\n",
        "\n",
        "# Plot samples of defective and non-defective casting\n",
        "fig, axes = plt.subplots(1, 2, figsize=(8,4))\n",
        "sample_def = plt.imread(dir_train_def+os.listdir(dir_train_def)[0])\n",
        "sample_ok = plt.imread(dir_train_ok+os.listdir(dir_train_ok)[0])\n",
        "axes[0].imshow(sample_def)\n",
        "axes[1].imshow(sample_ok)\n",
        "axes[0].set_title('Casting Sample: Defective', loc='left')\n",
        "axes[1].set_title('Casting Sample: OK', loc='left')\n",
        "axes[0].grid(False)\n",
        "axes[1].grid(False)\n",
        "plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-08-19T10:57:22.973767Z",
          "iopub.execute_input": "2021-08-19T10:57:22.97411Z",
          "iopub.status.idle": "2021-08-19T10:57:23.251416Z",
          "shell.execute_reply.started": "2021-08-19T10:57:22.974073Z",
          "shell.execute_reply": "2021-08-19T10:57:23.250516Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 597
        },
        "id": "LLJRPLpEKvfz",
        "outputId": "96a3e33a-a75e-4d57-9005-9bec56cd208f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/kaggle/input/real-life-industrial-dataset-of-casting-product/casting_data/casting_data/train/def_front/'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-4fb96344708b>\u001b[0m in \u001b[0;36m<cell line: 13>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# Plot samples of defective and non-defective casting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0msample_def\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdir_train_def\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdir_train_def\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0msample_ok\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdir_train_ok\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdir_train_ok\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_def\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/kaggle/input/real-life-industrial-dataset-of-casting-product/casting_data/casting_data/train/def_front/'"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x400 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "dcbM08CTllDS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We are performing a classification predictive modeling which involves assigning a class label (`Defective` or `OK`) for a given image of casting product. To prevent the model from making a biased prediction, the dataset must be checked for class imbalance. As shown in the following plot, there is uneven distribution between `Defective` and `OK`. However, considering the class imbalance is only by a small amount (6:4), the problem can be treated like a normal classification predictive modeling."
      ],
      "metadata": {
        "id": "1KbagGPXKvfz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create dataframe of class distribution\n",
        "n_train = [len(os.listdir(dir_train_def)), len(os.listdir(dir_train_ok))]\n",
        "n_test = [len(os.listdir(dir_test_def)), len(os.listdir(dir_test_ok))]\n",
        "dist_df = pd.DataFrame(\n",
        "    data=[n_train, n_test],\n",
        "    columns=['Defective', 'OK'],\n",
        "    index=['Train', 'Test'])\n",
        "\n",
        "# Visualize class distribution\n",
        "ax = dist_df.T.plot(kind='bar', stacked=True, rot=0, figsize=(8,5), colormap='Accent')\n",
        "ax.set_title('Class Distribution', loc='left', weight='bold')\n",
        "for bar in ax.patches:\n",
        "    ax.text(bar.get_x()+bar.get_width()-0.25,\n",
        "            bar.get_y()+bar.get_height()/2,\n",
        "            int(bar.get_height()),\n",
        "            ha='center', va='center', color='white')\n",
        "pct_def = 100*dist_df['Defective'].values.sum()/dist_df.values.sum()\n",
        "pct_ok = 100-pct_def\n",
        "ax.set_xticklabels([f'Class: Defective ({pct_def:.0f}%)',\n",
        "                    f'Class: OK ({pct_ok:.0f}%)'], weight='bold')\n",
        "plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-08-19T10:57:23.252412Z",
          "iopub.execute_input": "2021-08-19T10:57:23.252772Z",
          "iopub.status.idle": "2021-08-19T10:57:23.430399Z",
          "shell.execute_reply.started": "2021-08-19T10:57:23.252733Z",
          "shell.execute_reply": "2021-08-19T10:57:23.429508Z"
        },
        "trusted": true,
        "id": "iHpP9xKlKvf0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preprocessing\n",
        "\n",
        "The first step of preparing the data is to normalize pixel values (originally between 0 and 255) to a range of 0 to 1. This is done by passing the `rescale` arguments on instances of Keras ImageDataGenerator for train and test sets.\n",
        "\n",
        "With the train set generator we specify `validation_split=0.2` to reserve 20% of data for validation. The function `flow_from_directory()` is then used on the data generators for each of `train/` and `test/` directories. Arguments for data generation are also specified:\n",
        "- Target image size is 300Ã—300 pixels\n",
        "- `color_mode='grayscale'` to convert images as having 1 channel\n",
        "- Define class mapping: `0` for `OK`, `1` for `Defective`\n",
        "- `class_mode='binary'`  since there are two classes\n",
        "- Batch size fixed at 64"
      ],
      "metadata": {
        "id": "RfICLwXOKvf0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define instances of ImageDataGenerator\n",
        "train_gen = ImageDataGenerator(rescale=1./255, validation_split=0.2)\n",
        "test_gen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# Specify parameters/arguments for data generation\n",
        "img_size, batch_size, rand_seed = (300, 300), 64, 0\n",
        "arg_train = {'target_size': img_size,\n",
        "             'color_mode': 'grayscale',\n",
        "             'classes': {'ok_front': 0,\n",
        "                         'def_front': 1},\n",
        "             'class_mode': 'binary',\n",
        "             'batch_size': batch_size,\n",
        "             'seed': rand_seed}\n",
        "arg_test = {'target_size': img_size,\n",
        "            'color_mode': 'grayscale',\n",
        "            'classes': {'ok_front': 0,\n",
        "                        'def_front': 1},\n",
        "            'class_mode': 'binary',\n",
        "            'batch_size': batch_size,\n",
        "            'seed': rand_seed,\n",
        "            'shuffle': False}\n",
        "\n",
        "# Generate data by iterating through directories\n",
        "train_set = train_gen.flow_from_directory(\n",
        "    directory=dir_train, subset='training', **arg_train)\n",
        "valid_set = train_gen.flow_from_directory(\n",
        "    directory=dir_train, subset='validation', **arg_train)\n",
        "test_set = test_gen.flow_from_directory(\n",
        "    directory=dir_test, **arg_test)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-08-19T10:57:23.431691Z",
          "iopub.execute_input": "2021-08-19T10:57:23.432024Z",
          "iopub.status.idle": "2021-08-19T10:57:23.863823Z",
          "shell.execute_reply.started": "2021-08-19T10:57:23.431998Z",
          "shell.execute_reply": "2021-08-19T10:57:23.86312Z"
        },
        "trusted": true,
        "id": "V86zYsBtKvf1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Building\n",
        "\n",
        "We will use convolutional neural networks to approach the problem of classifying whether a casting is Defective or OK based on the given image. Almost universally used in computer vision applications, convolutional neural networks (CNN, convnets) is a type of deep-learning model that can look at groups of adjacent pixels in an area of an image and learn to find spatial patterns.\n",
        "\n",
        "<p style=\"text-align:center;\">\n",
        "    <img src=\"https://cezannec.github.io/assets/cnn_intro/CNN_ex.png\" alt=\"CNN architecture\" width=\"500\">\n",
        "</p>\n",
        "<p style=\"text-align:center;font-style:italic\">Image classification with a typical CNN architecture</p>\n",
        "\n",
        "As pictured above, CNN is made up of a number of layers: a series of convolutional layers (with activation), pooling layers, and at least one final fully-connected layer that produces a set of class scores for a given image. The convolutional layers of a CNN act as feature extractors; they extract shape and color patterns from the pixel values of training images.\n",
        "\n",
        "More in-depth explanations of how each CNN layer works can be found on [this awesome blog by Cezanne Camacho](https://cezannec.github.io/Convolutional_Neural_Networks/).\n",
        "\n",
        "For our model, we will adapt the general architectural principles of the [VGG models](https://arxiv.org/abs/1409.1556). The architecture involves stacking convolutional layers with small 3Ã—3 filters followed by a max pooling layer, together forming a block. These blocks can be repeated with increasing number of filters such as 32, 64, 128, 256.\n",
        "\n",
        "Padding is used on the convolutional layers to ensure same height and width between input and output. ReLU activation function is applied on every layer except the last one. Since a binary classification task requires a prediction of either a value of 0 or 1, the output layer is defined with 1 node and a sigmoid activation function.\n",
        "\n",
        "The model is fit with Adam optimizer (learning rate of 0.001) and with binary cross-entropy loss function. The metric with which to monitor model training is accuracy."
      ],
      "metadata": {
        "id": "1DITGKrPKvf1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define CNN model architecture\n",
        "cnn_model = Sequential([\n",
        "    # First block\n",
        "    Conv2D(32, 3, activation='relu', padding='same', strides=2,\n",
        "           input_shape=img_size+(1,)),\n",
        "    MaxPooling2D(pool_size=2, strides=2),\n",
        "    # Second block\n",
        "    Conv2D(64, 3, activation='relu', padding='same', strides=2),\n",
        "    MaxPooling2D(pool_size=2, strides=2),\n",
        "    # Flatenning\n",
        "    Flatten(),\n",
        "    # Fully connected layers\n",
        "    Dense(128, activation='relu'),\n",
        "    Dense(1, activation='sigmoid')        # Only 1 output\n",
        "])\n",
        "\n",
        "# Compile model\n",
        "cnn_model.compile(\n",
        "    optimizer=Adam(learning_rate=0.001),  # Default lr\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=['accuracy'])\n",
        "\n",
        "# Display summary of model architecture\n",
        "cnn_model.summary()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-08-19T10:57:23.867265Z",
          "iopub.execute_input": "2021-08-19T10:57:23.867517Z",
          "iopub.status.idle": "2021-08-19T10:57:24.877326Z",
          "shell.execute_reply.started": "2021-08-19T10:57:23.867492Z",
          "shell.execute_reply": "2021-08-19T10:57:24.876616Z"
        },
        "trusted": true,
        "id": "038guEK0Kvf2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Training and Evaluation\n",
        "\n",
        "The model is trained for 20 epochs, each requiring 83 steps for all image batches to pass through the network. The `ModelCheckpoint` callback is specified to save the model at an epoch that yields the best value of `val_loss` (when it is most minimized). We will later load the saved model to make predictions on the test set."
      ],
      "metadata": {
        "id": "3oVV8E1DKvf3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "# Fit model using train set and validation set\n",
        "n_epochs = 20\n",
        "cnn_model.fit(\n",
        "    train_set,\n",
        "    validation_data=valid_set,\n",
        "    epochs=n_epochs,\n",
        "    callbacks=ModelCheckpoint(\n",
        "        'CNN_Casting_Inspection.hdf5',\n",
        "        save_best_only=True,\n",
        "        monitor='val_loss'),\n",
        "    verbose=1)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-08-19T10:57:24.879593Z",
          "iopub.execute_input": "2021-08-19T10:57:24.879951Z",
          "iopub.status.idle": "2021-08-19T11:02:51.148142Z",
          "shell.execute_reply.started": "2021-08-19T10:57:24.879914Z",
          "shell.execute_reply": "2021-08-19T11:02:51.14706Z"
        },
        "trusted": true,
        "id": "6B5aGHY8Kvf3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot learning curve from model history\n",
        "histo_dict = cnn_model.history.history\n",
        "histo_df = pd.DataFrame(histo_dict, index=range(1,n_epochs+1))\n",
        "fig, ax = plt.subplots(figsize=(8,5))\n",
        "for m in histo_df.columns:\n",
        "    ax.plot(histo_df.index, m, data=histo_df)\n",
        "ax.set_xlabel('Epoch')\n",
        "ax.set_title('Learning Curve', loc='left', weight='bold')\n",
        "ax.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-08-19T11:02:51.149787Z",
          "iopub.execute_input": "2021-08-19T11:02:51.150206Z",
          "iopub.status.idle": "2021-08-19T11:02:51.356363Z",
          "shell.execute_reply.started": "2021-08-19T11:02:51.150164Z",
          "shell.execute_reply": "2021-08-19T11:02:51.355513Z"
        },
        "trusted": true,
        "id": "mbXOldfOKvf7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Accuracies of the model generally increase while loss decrease with increasing epoch. It can also be observed that training and validation curves are closely aligned, indicating that the model does not result in overfitting and may perform well on classifying images from the test set. Epoch 20 achieved best performance with the following results:\n",
        "- 99.81% training accuracy,\n",
        "- 98.94% validation accuracy,\n",
        "- 0.76% training loss, and\n",
        "- 2.78% validation loss."
      ],
      "metadata": {
        "id": "Av7GrZCBKvf8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Using Model to Classify New Images\n",
        "\n",
        "The trained model is used to predict the class of images that weren't previously included in the training and validation process. The classification will output a probability score between 0-1 and a threshold value of 0.5 is specified to separate the classes. A probability score that is equal to or greater than this threshold is classified as `Defective`, otherwise `OK`."
      ],
      "metadata": {
        "id": "6wjdmtm1Kvf8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load saved model\n",
        "best_model = load_model('./CNN_Casting_Inspection.hdf5')\n",
        "\n",
        "# Make predictions on images in the test set\n",
        "y_pred_prob = best_model.predict(test_set, verbose=1)\n",
        "y_pred = (y_pred_prob >= 0.5).reshape(-1,)\n",
        "y_true = test_set.classes[test_set.index_array]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-08-19T11:02:51.358022Z",
          "iopub.execute_input": "2021-08-19T11:02:51.358386Z",
          "iopub.status.idle": "2021-08-19T11:02:54.120609Z",
          "shell.execute_reply.started": "2021-08-19T11:02:51.35835Z",
          "shell.execute_reply": "2021-08-19T11:02:54.119819Z"
        },
        "trusted": true,
        "id": "u_T0qlZtKvf8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize the confusion matrix\n",
        "fig, ax = plt.subplots(figsize=(4,3))\n",
        "ax = sns.heatmap(confusion_matrix(y_true,y_pred), annot=True,\n",
        "                 annot_kws={'size':14, 'weight':'bold'},\n",
        "                 fmt='d', cbar=False, cmap='Blues')\n",
        "ax.set_xticklabels(['OK', 'Defective'])\n",
        "ax.set_yticklabels(['OK', 'Defective'], va='center')\n",
        "plt.tick_params(axis='both', labelsize=14, length=0)\n",
        "plt.ylabel('Actual', size=14, weight='bold')\n",
        "plt.xlabel('Predicted', size=14, weight='bold')\n",
        "plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-08-19T11:02:54.122034Z",
          "iopub.execute_input": "2021-08-19T11:02:54.122378Z",
          "iopub.status.idle": "2021-08-19T11:02:54.223273Z",
          "shell.execute_reply.started": "2021-08-19T11:02:54.122347Z",
          "shell.execute_reply": "2021-08-19T11:02:54.222324Z"
        },
        "trusted": true,
        "id": "9awCCT3dKvf9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_true, y_pred, digits=4))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-08-19T11:02:54.224594Z",
          "iopub.execute_input": "2021-08-19T11:02:54.224953Z",
          "iopub.status.idle": "2021-08-19T11:02:54.236775Z",
          "shell.execute_reply.started": "2021-08-19T11:02:54.224916Z",
          "shell.execute_reply": "2021-08-19T11:02:54.235897Z"
        },
        "trusted": true,
        "id": "Lq5PaiByKvf9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "An overall classification accuracy of 99.44% is achieved by the trained model which means that, out of 715 test images, there are 4 cases of misclassification. On predicting whether or not an image is of `Defective` casting, the model scores 99.78% on recall, 99.34% on precision, and 99.56% on F1-score.\n",
        "\n",
        "False negatives (mis-detections), i.e., cases when `Defective` castings are predicted as `OK`, must be minimized as it may cause revenue loss for the casting company due to rejection of the whole production order by customer. On the other hand, false positives (over-detection) may increase waste and production cost, not to mention unnecessary downtime.\n",
        "\n",
        "The metric recall helps us evaluate model performance when the cost of false negatives is high. Alternatively, when the cost of false positives is high, the metric precision is prioritized. However, since both cases of misclassification negatively impact the business, F1-score can be selected as a performance metric. F1-score is an overall measure of a model's accuracy that combines precision and recall.\n",
        "\n",
        "The following plots show prediction results and the probability score of some images from the test set. The visualization codes are adapted from [this notebook by Tomy Tjandra](https://www.kaggle.com/tomythoven/casting-inspection-with-data-augmentation-cnn)."
      ],
      "metadata": {
        "id": "jRUw09Z2Kvf-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class_map = {0: 'OK', 1: 'Defective'}\n",
        "images, labels = next(iter(test_set))\n",
        "images = images.reshape(batch_size,*img_size)\n",
        "\n",
        "fig, axes = plt.subplots(1, 3, figsize=(9, 4))\n",
        "fig.suptitle('Prediction on Test Images', y=0.98, weight='bold', size=14)\n",
        "for ax, img, label in zip(axes.flat, images, labels):\n",
        "    ax.imshow(img, cmap='gray')\n",
        "    [[pred_prob]] = best_model.predict(img.reshape(1, *img_size, -1))\n",
        "    pred_label = class_map[int(pred_prob>=0.5)]\n",
        "    true_label = class_map[label]\n",
        "    prob_class = 100*pred_prob if pred_label=='Defective' else 100*(1-pred_prob)\n",
        "    ax.set_title(f'Actual: {true_label}', size=12)\n",
        "    ax.set_xlabel(f'Predicted: {pred_label} ({prob_class:.2f}%)',\n",
        "                  color='g' if pred_label==true_label else 'r')\n",
        "    ax.set_xticks([])\n",
        "    ax.set_yticks([])\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-08-19T11:03:15.300912Z",
          "iopub.execute_input": "2021-08-19T11:03:15.301254Z",
          "iopub.status.idle": "2021-08-19T11:03:15.783966Z",
          "shell.execute_reply.started": "2021-08-19T11:03:15.301221Z",
          "shell.execute_reply": "2021-08-19T11:03:15.783093Z"
        },
        "trusted": true,
        "id": "RrWi7Y6tKvf-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "misclassified = np.nonzero(y_pred != y_true)[0]\n",
        "batch_num = misclassified//batch_size\n",
        "image_num = misclassified%batch_size\n",
        "\n",
        "fig, axes = plt.subplots(1, 4, figsize=(12, 4))\n",
        "fig.suptitle('Misclassified Test Images', y=0.98, weight='bold', size=14)\n",
        "for ax, bnum, inum in zip(axes.flat, batch_num, image_num):\n",
        "    images, labels = test_set[bnum]\n",
        "    img = images[inum]\n",
        "    ax.imshow(img.reshape(*img_size), cmap='gray')\n",
        "    [[pred_prob]] = best_model.predict(img.reshape(1, *img_size, -1))\n",
        "    pred_label = class_map[int(pred_prob>=0.5)]\n",
        "    true_label = class_map[labels[inum]]\n",
        "    prob_class = 100*pred_prob if pred_label=='Defective' else 100*(1-pred_prob)\n",
        "    ax.set_title(f'Actual: {true_label}', size=12)\n",
        "    ax.set_xlabel(f'Predicted: {pred_label} ({prob_class:.2f}%)',\n",
        "                  color='g' if pred_label==true_label else 'r')\n",
        "    ax.set_xticks([])\n",
        "    ax.set_yticks([])\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-08-19T11:03:41.093077Z",
          "iopub.execute_input": "2021-08-19T11:03:41.093424Z",
          "iopub.status.idle": "2021-08-19T11:03:42.026737Z",
          "shell.execute_reply.started": "2021-08-19T11:03:41.093393Z",
          "shell.execute_reply": "2021-08-19T11:03:42.025777Z"
        },
        "trusted": true,
        "id": "etqUQMBNKvf_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Conclusion"
      ],
      "metadata": {
        "id": "_YzBQnUPKvf_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A convolutional neural networks model was created to classify images of a casting product as either Defective or OK and achieved a good performance based on F1-score (99.56%). Results of this project suggest viability of deep learning method in automating visual inspection. Incorporation of this method in the production line can provide support for trained inspectors in making better assessments of product quality."
      ],
      "metadata": {
        "id": "UQgzTNhhKvf_"
      }
    }
  ]
}